{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter selection, Validation, and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most models have parameters that influence how complex a model they can learn. Remember using `KNeighborsRegressor`.\n",
    "If we change the number of neighbors we consider, we get a smoother and smoother prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/plot_kneigbors_regularization.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above figure, we see fits for three different values of ``n_neighbors``.\n",
    "For ``n_neighbors=2``, the data is overfit, the model is too flexible and can adjust too much to the noise in the training data. For ``n_neighbors=20``, the model is not flexible enough, and can not model the variation in the data appropriately.\n",
    "\n",
    "In the middle, for ``n_neighbors = 5``, we have found a good mid-point. It fits\n",
    "the data fairly well, and does not suffer from the overfit or underfit\n",
    "problems seen in the figures on either side. What we would like is a\n",
    "way to quantitatively identify overfit and underfit, and optimize the\n",
    "hyperparameters (in this case, the polynomial degree d) in order to\n",
    "determine the best algorithm.\n",
    "\n",
    "We trade off remembering too much about the particularities and noise of the training data vs. not modeling enough of the variability. This is a trade-off that needs to be made in basically every machine learning application and is a central concept, called bias-variance-tradeoff or \"overfitting vs underfitting\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/overfitting_underfitting_cartoon.svg\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters, Over-fitting, and Under-fitting\n",
    "\n",
    "Unfortunately, there is no general rule how to find the sweet spot, and so machine learning practitioners have to find the best trade-off of model-complexity and generalization by trying several hyperparameter settings. Hyperparameters are the internal knobs or tuning parameters of a machine learning algorithm (in contrast to model parameters that the algorithm learns from the training data -- for example, the weight coefficients of a linear regression model); the number of *k* in K-nearest neighbors is such a hyperparameter.\n",
    "\n",
    "Most commonly this \"hyperparameter tuning\" is done using a brute force search, for example over multiple values of ``n_neighbors``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors: 1, average score: 0.573320\n",
      "n_neighbors: 3, average score: 0.687493\n",
      "n_neighbors: 5, average score: 0.758279\n",
      "n_neighbors: 10, average score: 0.713713\n",
      "n_neighbors: 20, average score: 0.642866\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# generate toy dataset:\n",
    "x = np.linspace(-3, 3, 100)\n",
    "rng = np.random.RandomState(42)\n",
    "y = np.sin(4 * x) + x + rng.normal(size=len(x))\n",
    "X = x[:, np.newaxis]\n",
    "\n",
    "cv = KFold(shuffle=True)\n",
    "\n",
    "# for each parameter setting do cross-validation:\n",
    "for n_neighbors in [1, 3, 5, 10, 20]:\n",
    "    scores = cross_val_score(KNeighborsRegressor(n_neighbors=n_neighbors), X, y, cv=cv)\n",
    "    print(\"n_neighbors: %d, average score: %f\" % (n_neighbors, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a function in scikit-learn, called ``validation_plot`` to reproduce the cartoon figure above. It plots one parameter, such as the number of neighbors, against training and validation error (using cross-validation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSqXQpKCUUiqFJgWllFIp/h+jO794alYUPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f25759391d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "n_neighbors = [1, 3, 5, 10, 20, 50]\n",
    "train_scores, test_scores = validation_curve(KNeighborsRegressor(), X, y, param_name=\"n_neighbors\",\n",
    "                                             param_range=n_neighbors, cv=cv)\n",
    "plt.plot(n_neighbors, train_scores.mean(axis=1), 'b', label=\"train accuracy\")\n",
    "plt.plot(n_neighbors, test_scores.mean(axis=1), 'g', label=\"test accuracy\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of neighbors')\n",
    "plt.xlim([50, 0])\n",
    "plt.legend(loc=\"best\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Note that many neighbors mean a \"smooth\" or \"simple\" model, so the plot uses a reverted x axis.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple parameters are important, like the parameters ``C`` and ``gamma`` in an ``SVM`` (more about that later), all possible combinations are tried:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.001000, gamma: 0.001000, average score: -0.044285\n",
      "C: 0.001000, gamma: 0.010000, average score: -0.034980\n",
      "C: 0.001000, gamma: 0.100000, average score: -0.085853\n",
      "C: 0.001000, gamma: 1.000000, average score: -0.081303\n",
      "C: 0.010000, gamma: 0.001000, average score: -0.018214\n",
      "C: 0.010000, gamma: 0.010000, average score: -0.081502\n",
      "C: 0.010000, gamma: 0.100000, average score: 0.031467\n",
      "C: 0.010000, gamma: 1.000000, average score: 0.038719\n",
      "C: 0.100000, gamma: 0.001000, average score: -0.017532\n",
      "C: 0.100000, gamma: 0.010000, average score: 0.169627\n",
      "C: 0.100000, gamma: 0.100000, average score: 0.519197\n",
      "C: 0.100000, gamma: 1.000000, average score: 0.461351\n",
      "C: 1.000000, gamma: 0.001000, average score: 0.198315\n",
      "C: 1.000000, gamma: 0.010000, average score: 0.503706\n",
      "C: 1.000000, gamma: 0.100000, average score: 0.667784\n",
      "C: 1.000000, gamma: 1.000000, average score: 0.688941\n",
      "C: 10.000000, gamma: 0.001000, average score: 0.563645\n",
      "C: 10.000000, gamma: 0.010000, average score: 0.616970\n",
      "C: 10.000000, gamma: 0.100000, average score: 0.644517\n",
      "C: 10.000000, gamma: 1.000000, average score: 0.740794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "# each parameter setting do cross-validation:\n",
    "for C in [0.001, 0.01, 0.1, 1, 10]:\n",
    "    for gamma in [0.001, 0.01, 0.1, 1]:\n",
    "        scores = cross_val_score(SVR(C=C, gamma=gamma), X, y, cv=cv)\n",
    "        print(\"C: %f, gamma: %f, average score: %f\" % (C, gamma, np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As this is such a very common pattern, there is a built-in class for this in scikit-learn, ``GridSearchCV``. ``GridSearchCV`` takes a dictionary that describes the parameters that should be tried and a model to train.\n",
    "\n",
    "The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv, verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a *meta-estimator*. It takes an estimator like SVR above, and creates a new estimator, that behaves exactly the same - in this case, like a regressor.\n",
    "So we can call ``fit`` on it, to train it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.254876, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.242109, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-0.003369, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.252754, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.239737, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-0.001335, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.243247, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-0.229388, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] ............... C=0.001, gamma=0.1, score=0.007464, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.244912, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-0.231267, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................. C=0.001, gamma=1, score=0.005814, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.252545, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.239496, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-0.001125, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.225747, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-0.215994, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] ............... C=0.01, gamma=0.01, score=0.018278, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ............... C=0.01, gamma=0.1, score=-0.109127, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ............... C=0.01, gamma=0.1, score=-0.096300, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ................ C=0.01, gamma=0.1, score=0.095169, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ................. C=0.01, gamma=1, score=-0.130784, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ................. C=0.01, gamma=1, score=-0.114529, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] .................. C=0.01, gamma=1, score=0.081409, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.222234, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-0.213626, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] ............... C=0.1, gamma=0.001, score=0.020244, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ............... C=0.1, gamma=0.01, score=-0.015377, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.039501, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ................ C=0.1, gamma=0.01, score=0.184184, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.371600, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.467089, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................. C=0.1, gamma=0.1, score=0.493806, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.328486, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.461464, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] ................... C=0.1, gamma=1, score=0.455013, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.002055, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.046565, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................. C=1, gamma=0.001, score=0.196917, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.510993, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.556503, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.590643, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.646150, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.617256, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................... C=1, gamma=0.1, score=0.663266, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.706274, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.655740, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................... C=1, gamma=1, score=0.740845, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.497328, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.556853, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.605823, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.587922, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.583890, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................. C=10, gamma=0.01, score=0.652222, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.648962, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.616012, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................. C=10, gamma=0.1, score=0.674313, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.760199, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.721689, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................... C=10, gamma=1, score=0.771254, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=3, random_state=None, shuffle=True),\n",
       "       error_score='raise',\n",
       "       estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=3)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What ``fit`` does is a bit more involved then what we did above. First, it runs the same loop with cross-validation, to find the best parameter combination.\n",
    "Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as with all models, we can use ``predict`` or ``score``:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.79762875, -1.74054091, -1.71412904, -1.72272347, -1.76880247,\n",
       "       -1.8527208 , -1.97255382, -2.12407501, -2.30087676, -2.49463429,\n",
       "       -2.695503  , -2.89262935, -3.07474705, -3.23082299, -3.35071314,\n",
       "       -3.42578612, -3.44947391, -3.41771237, -3.32924127, -3.18574205,\n",
       "       -2.9918017 , -2.75470244, -2.48404785, -2.19124658, -1.88888388,\n",
       "       -1.59001819, -1.30744475, -1.05297034, -0.8367425 , -0.66667333,\n",
       "       -0.54799235, -0.4829551 , -0.4707249 , -0.50743515, -0.58642852,\n",
       "       -0.69865919, -0.83323456, -0.97806438, -1.12057877, -1.24847261,\n",
       "       -1.35043139, -1.41679516, -1.44012026, -1.41560488, -1.3413525 ,\n",
       "       -1.21845724, -1.05090633, -0.84530623, -0.61045003, -0.35675398,\n",
       "       -0.09559933,  0.16137852,  0.40300817,  0.61926205,  0.80185531,\n",
       "        0.94472644,  1.04437082,  1.10000798,  1.11357463,  1.08954695,\n",
       "        1.03460678,  0.95717608,  0.86685224,  0.7737823 ,  0.68801751,\n",
       "        0.61888941,  0.57444669,  0.56098656,  0.58270777,  0.64150352,\n",
       "        0.73690334,  0.86616306,  1.02449275,  1.20540425,  1.40115266,\n",
       "        1.60324152,  1.80295801,  1.99190412,  2.16249073,  2.3083654 ,\n",
       "        2.42474939,  2.50866621,  2.55905134,  2.57674055,  2.56434191,\n",
       "        2.52600389,  2.46709789,  2.39383845,  2.31286721,  2.23082834,\n",
       "        2.15396216,  2.0877418 ,  2.03657355,  2.00357681,  1.99045342,\n",
       "        1.99745004,  2.02341108,  2.06591373,  2.12147209,  2.18579347])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "You can inspect the best parameters found by ``GridSearchCV`` in the ``best_params_`` attribute, and the best score in the ``best_score_`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75113863484\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 10, 'gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But you can investigate the performance and much more for each set of parameter values by accessing the `cv_results_` attributes. The `cv_results_` attribute is a dictionary where each key is a string and each value is array. It can therefore be used to make a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(grid.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['split0_test_score', 'split1_test_score', 'split2_test_score', 'mean_test_score', 'std_test_score', 'rank_test_score', 'split0_train_score', 'split1_train_score', 'split2_train_score', 'mean_train_score', 'std_train_score', 'mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time', 'param_C', 'param_gamma', 'params'])\n"
     ]
    }
   ],
   "source": [
    "print(grid.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>-0.167666</td>\n",
       "      <td>-0.001912</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.001}</td>\n",
       "      <td>20</td>\n",
       "      <td>-0.254876</td>\n",
       "      <td>-0.003394</td>\n",
       "      <td>-0.242109</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>-0.003369</td>\n",
       "      <td>-0.002576</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.115423</td>\n",
       "      <td>0.001553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000851</td>\n",
       "      <td>-0.165490</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.01}</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.252754</td>\n",
       "      <td>-0.001509</td>\n",
       "      <td>-0.239737</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>-0.001335</td>\n",
       "      <td>-0.000541</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.115329</td>\n",
       "      <td>0.001584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>-0.155939</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 0.1}</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.243247</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>-0.229388</td>\n",
       "      <td>0.010876</td>\n",
       "      <td>0.007464</td>\n",
       "      <td>0.008865</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.114818</td>\n",
       "      <td>0.001858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>-0.157670</td>\n",
       "      <td>0.007615</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 0.001, 'gamma': 1}</td>\n",
       "      <td>17</td>\n",
       "      <td>-0.244912</td>\n",
       "      <td>0.004950</td>\n",
       "      <td>-0.231267</td>\n",
       "      <td>0.009720</td>\n",
       "      <td>0.005814</td>\n",
       "      <td>0.008175</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.114871</td>\n",
       "      <td>0.001987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-0.165270</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 0.01, 'gamma': 0.001}</td>\n",
       "      <td>18</td>\n",
       "      <td>-0.252545</td>\n",
       "      <td>-0.001303</td>\n",
       "      <td>-0.239496</td>\n",
       "      <td>0.002436</td>\n",
       "      <td>-0.001125</td>\n",
       "      <td>-0.000349</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.115322</td>\n",
       "      <td>0.001586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  mean_score_time  mean_test_score  mean_train_score param_C  \\\n",
       "0       0.001001         0.000502        -0.167666         -0.001912   0.001   \n",
       "1       0.000817         0.000851        -0.165490          0.000059   0.001   \n",
       "2       0.000541         0.000310        -0.155939          0.008692   0.001   \n",
       "3       0.000719         0.000336        -0.157670          0.007615   0.001   \n",
       "4       0.000552         0.000290        -0.165270          0.000261    0.01   \n",
       "\n",
       "  param_gamma                        params  rank_test_score  \\\n",
       "0       0.001  {'C': 0.001, 'gamma': 0.001}               20   \n",
       "1        0.01   {'C': 0.001, 'gamma': 0.01}               19   \n",
       "2         0.1    {'C': 0.001, 'gamma': 0.1}               16   \n",
       "3           1      {'C': 0.001, 'gamma': 1}               17   \n",
       "4       0.001   {'C': 0.01, 'gamma': 0.001}               18   \n",
       "\n",
       "   split0_test_score  split0_train_score  split1_test_score  \\\n",
       "0          -0.254876           -0.003394          -0.242109   \n",
       "1          -0.252754           -0.001509          -0.239737   \n",
       "2          -0.243247            0.006336          -0.229388   \n",
       "3          -0.244912            0.004950          -0.231267   \n",
       "4          -0.252545           -0.001303          -0.239496   \n",
       "\n",
       "   split1_train_score  split2_test_score  split2_train_score  std_fit_time  \\\n",
       "0            0.000233          -0.003369           -0.002576      0.000329   \n",
       "1            0.002229          -0.001335           -0.000541      0.000171   \n",
       "2            0.010876           0.007464            0.008865      0.000024   \n",
       "3            0.009720           0.005814            0.008175      0.000181   \n",
       "4            0.002436          -0.001125           -0.000349      0.000026   \n",
       "\n",
       "   std_score_time  std_test_score  std_train_score  \n",
       "0        0.000212        0.115423         0.001553  \n",
       "1        0.000528        0.115329         0.001584  \n",
       "2        0.000037        0.114818         0.001858  \n",
       "3        0.000043        0.114871         0.001987  \n",
       "4        0.000015        0.115322         0.001586  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "cv_results = pd.DataFrame(grid.cv_results_)\n",
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.751139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.701006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.646454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.642263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.607810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_C param_gamma  mean_test_score\n",
       "19      10           1         0.751139\n",
       "15       1           1         0.701006\n",
       "18      10         0.1         0.646454\n",
       "14       1         0.1         0.642263\n",
       "17      10        0.01         0.607810"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_tiny = cv_results[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "cv_results_tiny.sort_values(by='mean_test_score', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a problem with using this score for evaluation, however. You might be making what is called a multiple hypothesis testing error. If you try very many parameter settings, some of them will work better just by chance, and the score that you obtained might not reflect how your model would perform on new unseen data.\n",
    "Therefore, it is good to split off a separate test-set before performing grid-search. This pattern can be seen as a training-validation-test split, and is common in machine learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/grid_search_cross_validation.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do this very easily by splitting of some test data using ``train_test_split``, training ``GridSearchCV`` on the training set, and applying the ``score`` method to the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "cv = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=cv)\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at the parameters that were selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some practitioners go for an easier scheme, splitting the data simply into three parts, training, validation and testing. This is a possible alternative if your training set is very large, or it is infeasible to train many models using cross-validation because training a model takes very long.\n",
    "You can do this with scikit-learn for example by splitting of a test-set and then applying GridSearchCV with ShuffleSplit cross-validation with a single iteration:\n",
    "\n",
    "<img src=\"figures/train_validation_test2.svg\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 1 folds for each of 20 candidates, totalling 20 fits\n",
      "[CV] C=0.001, gamma=0.001 ............................................\n",
      "[CV] ............ C=0.001, gamma=0.001, score=-2.160737, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.01 .............................................\n",
      "[CV] ............. C=0.001, gamma=0.01, score=-2.156035, total=   0.0s\n",
      "[CV] C=0.001, gamma=0.1 ..............................................\n",
      "[CV] .............. C=0.001, gamma=0.1, score=-2.136446, total=   0.0s\n",
      "[CV] C=0.001, gamma=1 ................................................\n",
      "[CV] ................ C=0.001, gamma=1, score=-2.140451, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.001 .............................................\n",
      "[CV] ............. C=0.01, gamma=0.001, score=-2.155529, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.01 ..............................................\n",
      "[CV] .............. C=0.01, gamma=0.01, score=-2.108992, total=   0.0s\n",
      "[CV] C=0.01, gamma=0.1 ...............................................\n",
      "[CV] ............... C=0.01, gamma=0.1, score=-1.818230, total=   0.0s\n",
      "[CV] C=0.01, gamma=1 .................................................\n",
      "[CV] ................. C=0.01, gamma=1, score=-1.854643, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001 ..............................................\n",
      "[CV] .............. C=0.1, gamma=0.001, score=-2.104021, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01 ...............................................\n",
      "[CV] ............... C=0.1, gamma=0.01, score=-1.483753, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1 ................................................\n",
      "[CV] ................ C=0.1, gamma=0.1, score=-0.332961, total=   0.0s\n",
      "[CV] C=0.1, gamma=1 ..................................................\n",
      "[CV] .................. C=0.1, gamma=1, score=-0.288391, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................ C=1, gamma=0.001, score=-1.413816, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................. C=1, gamma=0.01, score=0.061613, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] .................. C=1, gamma=0.1, score=-0.342031, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] .................... C=1, gamma=1, score=-0.262183, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................ C=10, gamma=0.001, score=0.121756, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................ C=10, gamma=0.01, score=-0.246796, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] ................. C=10, gamma=0.1, score=-0.484403, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] ................... C=10, gamma=1, score=-0.154538, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 out of  20 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.567090677113258"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10], 'gamma': [0.001, 0.01, 0.1, 1]}\n",
    "single_split_cv = ShuffleSplit(n_splits=1)\n",
    "\n",
    "grid = GridSearchCV(SVR(), param_grid=param_grid, cv=single_split_cv, verbose=3)\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "grid.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is much faster, but might result in worse hyperparameters and therefore worse results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7262035177984737"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(SVR(), param_grid=param_grid)\n",
    "clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>EXERCISE</b>:\n",
    "     <ul>\n",
    "      <li>\n",
    "      Apply grid-search to find the best setting for the number of neighbors in ``KNeighborsClassifier``, and apply it to the digits dataset.\n",
    "      </li>\n",
    "    </ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.970803, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.988930, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.988930, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n",
      "[CV] .................... n_neighbors=1, score=0.988764, total=   0.0s\n",
      "[CV] n_neighbors=1 ...................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................... n_neighbors=1, score=0.988636, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.981752, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.988930, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.985240, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.985019, total=   0.0s\n",
      "[CV] n_neighbors=3 ...................................................\n",
      "[CV] .................... n_neighbors=3, score=0.984848, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.985401, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.996310, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.974170, total=   0.0s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.985019, total=   0.1s\n",
      "[CV] n_neighbors=5 ...................................................\n",
      "[CV] .................... n_neighbors=5, score=0.984848, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.978102, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.981550, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.977860, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.981273, total=   0.0s\n",
      "[CV] n_neighbors=10 ..................................................\n",
      "[CV] ................... n_neighbors=10, score=0.984848, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.927007, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.929889, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.952030, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.921348, total=   0.0s\n",
      "[CV] n_neighbors=50 ..................................................\n",
      "[CV] ................... n_neighbors=50, score=0.958333, total=   0.0s\n",
      "Score on test set: 0.991111\n",
      "Best parameters: {'n_neighbors': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    3.8s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "digits = load_digits()\n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, random_state=0)\n",
    "\n",
    "param_grid = {'n_neighbors': [1, 3, 5, 10, 50]}\n",
    "gs = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=5, verbose=3)\n",
    "gs.fit(X_train, y_train)\n",
    "print(\"Score on test set: %f\" % gs.score(X_test, y_test))\n",
    "print(\"Best parameters: %s\" % gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/14_grid_search.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
